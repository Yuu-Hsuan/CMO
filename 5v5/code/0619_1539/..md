
# 最終目標:
1. 用GPU把worker網路拆開
   * 方便併行處理

# 下個目標:
1. 套用學長的 Global & Local state
   * Global:`5*5+4*5`
     * 我方(5)*(5個船):[是否存在,與目的地的相對距離,與目的地的相對方向（sin表示),與目的地的相對方向（cos表示),彈藥持有比率]
     * 敵方(4)*(5個船):[是否存在,與目的地的相對距離,與目的地的相對方向（sin表示),與目的地的相對方向（cos表示)]
   * Local:`7+5*4+4*3`維
     * 自身(7):[與目的地的相對距離,與目的地的相對方向（sin表示),與目的地的相對方向（cos表示),敵人是否存在(看敵),敵人存活比率,彈藥持有比率,步數比率(結束趨於0(1-0遞減))]
     * 友軍(5)*(5-1個船):[是否存在,與目的地的相對距離,與目的地的相對方向（sin表示),與目的地的相對方向（cos表示),彈藥持有比率]
     * 敵軍(4)*(5個船):[是否存在,與目的地的相對距離,與目的地的相對方向（sin表示),與目的地的相對方向（cos表示)]
       

2. 用 `move_to` 的 `reward`

3. Critic：改成 Linear→ReLU(不會負`softplus`)→256→ReLU(不會負`softplus`)→1

# 此版本完成:
1. Action改成:[往前，往左，往右，發射雄山飛彈]
   
2. 獎勵:`ext:int=1:100`
   * ext:計算各艘船的獎勵再除以我方船艦數(若船死則之後`reward=0`；若船上岸則`reward+=1`，之後不給reward)
   * int:用`cossim+1` >>> `(100*ext+1*int)`
     
3. 在logger輸出的最終距離 必須用動態分母值 (當前的船數)

4. 熵：每 1 episode 乘 0.995，而非每 step

5. Critic：改成 Linear→ReLU→256→ReLU→1

# 結果
(若不會收斂，改原本的action)
