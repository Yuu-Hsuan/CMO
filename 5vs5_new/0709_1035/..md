# 架構 : FeUdal + 雙 Actor-Critic + 雙 GAE
1. 目前: manager 用一個 critic； n 個 worker 共用一個 critic (共兩個critic)
2. manager 生成 n 個不同 `goal` & `instristic reward` 給 n 個 worker ( worke數 = 船艦數 )

# 觀察:
1. 有時訓練效果欠佳 (回合數難收斂、卡在最多只有四艘船抵達)

# 下一步:
1. per-agent-critic : 每個 worker 各一個 critic (方便之後任務差異大時適應新的訓練環境)
2. Reward shapping : 把下個狀態考慮進去
3. loss 拆開分析

# 圖:
1. 約 110回合(140000步) 開始繞圈
2. 約 70回合(105000步) 表現最佳
![image](https://github.com/Yuu-Hsuan/CMO/blob/main/5vs5_new/0709_1035/graph/1.png)
![image](https://github.com/Yuu-Hsuan/CMO/blob/main/5vs5_new/0709_1035/graph/2.png)
