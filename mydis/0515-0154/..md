# 改善raw_goal更新問題
## 下個目標:
改善T條件問題:(噴錯)
```
--- a/sample_agent.py
+++ b/sample_agent.py
@@     def train_on_episode(self):
-        # 從 episode_memory 拆欄
+        # 從 episode_memory 拆欄
         states, actions, ext_rewards, next_states, dones, raw_goals = zip(*self.episode_memory)
         T = len(ext_rewards)
         # 這裡用 dilation 代表 Manager 的目標展開長度
         dilation = self.args.manager_dilation

+        # ==== Method 1 guard: 如果本集太短，跳過 intrinsic training ==== 
+        if T <= dilation:
+            self.logger.warning(
+                f"Episode length {T} ≤ dilation {dilation}, skip intrinsic+worker training"
+            )
+            # 只做 Manager 的 extrinsic update 或完全跳過
+            # 這裡我們選擇直接 return，不做任何參數更新
+            return
+        # ================================================================
 
         # 轉 tensor
         states = torch.tensor(states, dtype=torch.float32, device=self.device)
```
# 目前結果:
![image](https://github.com/Yuu-Hsuan/CMO/blob/main/mydis/0515-0154/2.png)
